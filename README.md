# README

> 为了防止忘了怎么用写的。

## 这是什么？

这个是用结巴分词写的一个纯文本中文分词，统计分词出现频率，并能搜索想要的关键词的评论。因为是用python写的分词代码，用node写的搜索，所以还没整合。打算有空用node写分词。然后融合到我的[nodc](https://github.com/bubao/nodc)中。


## 需要什么

- **node**运行环境
- **python**运行环境
- 一台配置不是很低的电脑
- 耐心，毕竟代码还没有优化

## 怎么用

### 手动

1. 把要转换的文件放在在当前文件夹，并改名为`源文件.txt`
2. cmd下运行 `python index.py`，等待完成，等待完成期间可以在`Search.js`文件里把想要搜索的关键字填在数组里，保存好
3. 完成第二步，接着执行`node  Search.js`，等待完成。
4. 关键词在`keyWord.txt`，词频在`getObj.json`中

### 自动脚本

1. 把要转换的文件放在在当前文件夹，并改名为`源文件.txt`
2. 命令行下执行`sh main.sh`
4. 关键词在`keyWord.txt`，词频在`getObj.json`中

## END

